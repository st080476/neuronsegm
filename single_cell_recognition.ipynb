{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport os\n\ndef rle2mask(mask_rle, shape):\n    '''\n    Функция для преобразования RLE маски в 2D numpy массив.\n    :param mask_rle: run-length as string formatted (start length)\n    :param shape: (height, width) of array to return\n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape, order='F')\n\n# Загрузка метаданных\nmetadata = pd.read_csv('/kaggle/input/sartorius-cell-instance-segmentation/train.csv')\n\n# Загрузка изображений и масок\ndata_path = '/kaggle/input/sartorius-cell-instance-segmentation/train'\nimages = []  # список для хранения изображений\nmasks = []   # список для хранения масок\n\nfor file_name in os.listdir(data_path):\n    # Загрузка изображения\n    img = Image.open(os.path.join(data_path, file_name))\n    img = img.resize((416, 416))  # Изменение размера изображения для совместимости с YOLO\n    images.append(np.array(img))\n    \n    # Загрузка соответствующей маски\n    img_id = file_name.split('.')[0]  # Идентификатор изображения\n    mask_rle = metadata.loc[metadata['id'] == img_id, 'annotation'].values[0]  # RLE маска\n    mask = rle2mask(mask_rle, img.size)\n    masks.append(mask)\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\n\nfor img in images:\n    # Подготовка изображения\n    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  # Переход от RGB к BGR, т.к. OpenCV использует BGR\n    img = img / 255.0  # Нормализация изображения\n    img = torch.from_numpy(img).permute(2, 0, 1).float().to('cuda' if torch.cuda.is_available() else 'cpu')  # Переупорядочивание осей и перевод изображения в тензор PyTorch\n    img = img.unsqueeze(0)  # Добавление размерности для пакета\n\n    with torch.no_grad():\n        # Прямой проход (forward pass)\n        outputs = model(img)\n\n  \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# Путь к директории\n#directory = '/kaggle/working'\n\n# Рекурсивно удалить все файлы в директории и поддиректориях\n#for root, dirs, files in os.walk(directory):\n#    for file_name in files:\n#        file_path = os.path.join(root, file_name)\n#os.remove(file_path)\n\n!pip install torchvision yolov5        \nimport subprocess\npackages = [\n'aiobotocore<1.29.77,>=1.29.76',\n'jupyter-lsp>=2.0.0',\n'shapely>=2',\n'packaging>=22.0',\n'scipy<1.10,>=1.4.1'\n]\nfor package in packages:\n    subprocess.call(['pip', 'install', package])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport glob\nimport json\nimport shutil\nimpoty yaml\n\ndef process_annotations(json_path, annotations_path):\n    with open(json_path) as f:\n        data = json.load(f)\n\n    temp_annotations_path = os.path.join(annotations_path, 'temp')\n    os.makedirs(temp_annotations_path, exist_ok=True)\n\n    for annotation_id, annotation_data in data['annotations'].items():\n        image_id = annotation_data['image_id']\n        category_id = annotation_data['category_id'] - 1\n        bbox = annotation_data['bbox']\n        xmin, ymin, width, height = bbox\n\n        image_data = next(image for image in data['images'] if image['id'] == image_id)\n        img_width, img_height = image_data['width'], image_data['height']\n\n        x_center = (xmin + width / 2) / img_width\n        y_center = (ymin + height / 2) / img_height\n        bbox_width = width / img_width\n        bbox_height = height / img_height\n\n        annotation_file = os.path.join(temp_annotations_path, f'{annotation_id}.txt')\n        with open(annotation_file, 'a') as f:\n            f.write(f'{category_id} {x_center} {y_center} {bbox_width} {bbox_height}\\n')\n\n    move_annotations(temp_annotations_path, annotations_path)\n    os.rmdir(temp_annotations_path)\n\ndef move_annotations(source_folder, destination_folder):\n    os.makedirs(destination_folder, exist_ok=True)\n\n    for file_name in os.listdir(source_folder):\n        source_path = os.path.join(source_folder, file_name)\n        destination_path = os.path.join(destination_folder, file_name)\n\n        if os.path.exists(destination_path):\n            os.remove(destination_path)\n\n        shutil.move(source_path, destination_path)\n\ndef create_data_files(image_dir, output_train_file, output_val_file, train_ratio=0.8):\n    image_files = glob.glob(os.path.join(image_dir, '*.png'))\n    num_images = len(image_files)\n    num_train = int(train_ratio * num_images)\n    train_files = image_files[:num_train]\n    val_files = image_files[num_train:]\n\n    with open(output_train_file, 'w') as f:\n        for path in train_files:\n            f.write(path + '\\n')\n\n    if output_val_file:\n        with open(output_val_file, 'w') as f:\n            for path in val_files:\n                f.write(path + '\\n')\n\n# Путь к папке LIVECell_dataset_2021\ndataset_folder = '/kaggle/input/sartorius-cell-instance-segmentation/LIVECell_dataset_2021'\n\n# Путь к папке, где будут храниться аннотации в формате YOLO\nyolo_annotations_path = '/kaggle/temp/data/annotations'\n\n# Обработка аннотаций для папки LIVECell\nlivecell_annotations_folder = os.path.join(dataset_folder, 'annotations/LIVECell')\nprocess_annotations(os.path.join(livecell_annotations_folder, 'livecell_coco_test.json'), yolo_annotations_path)\nprocess_annotations(os.path.join(livecell_annotations_folder, 'livecell_coco_train.json'), yolo_annotations_path)\nprocess_annotations(os.path.join(livecell_annotations_folder, 'livecell_coco_val.json'), yolo_annotations_path)\n\n# Обработка аннотаций для папки LiveCell_single_cells\nlivecell_single_cells_annotations_folder = os.path.join(dataset_folder, 'annotations/LIVECell_single_cells')\n\nfor category_folder in os.listdir(livecell_single_cells_annotations_folder):\n    category_folder_path = os.path.join(livecell_single_cells_annotations_folder, category_folder)\n    \n    if os.path.isdir(category_folder_path):\n        test_file = f'livecell_{category_folder}_test.json'\n        train_file = f'livecell_{category_folder}_train.json'\n        val_file = f'livecell_{category_folder}_val.json'\n        \n        process_annotations(os.path.join(category_folder_path, test_file), yolo_annotations_path)\n        process_annotations(os.path.join(category_folder_path, train_file), yolo_annotations_path)\n        process_annotations(os.path.join(category_folder_path, val_file), yolo_annotations_path)\n\n# Путь к папке с изображениями для train.txt и val.txt\nlivecell_train_val_images_folder = os.path.join(dataset_folder, 'images/livecell_train_val_images')\n\n# Создание train.txt и val.txt\ncreate_data_files(livecell_train_val_images_folder, '/kaggle/temp/data/annotations/train.txt',\n                  '/kaggle/temp/data/annotations/val.txt', train_ratio=0.8)\n\n# Путь к папке с изображениями для test.txt\nlivecell_test_images_folder = os.path.join(dataset_folder, 'images/livecell_test_images')\n\n# Создание test.txt\ncreate_data_files(livecell_test_images_folder, '/kaggle/temp/data/annotations/test.txt', '')\n\n# Путь к папке с изображениями для test.txt (дополнительная папка test)\ntest_images_folder = '/kaggle/input/sartorius-cell-instance-segmentation/test'\n\n# Создание test.txt для дополнительной папки test\ncreate_data_files(test_images_folder, '/kaggle/temp/data/annotations/test.txt', '')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport yaml\nfrom torchvision import datasets\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import ToTensor, Lambda, Compose\nimport torch\nimport matplotlib.pyplot as plt\n\n# Путь к папке для сохранения YAML-файла\noutput_folder = '/kaggle/temp/data'\nos.makedirs(output_folder, exist_ok=True)\n\n# The structure of the data for YAML\ndata = {\n    'nc': 2,  # Количество классов\n    'names': ['neuron', 'background'], # Имена классов\n    'depth_multiple': 0.33,\n    'width_multiple':0.50,\n    'anchors': [\n        [10, 13, 16, 30, 33, 23],\n        [30, 61, 62, 45, 59, 119],\n        [116, 90, 156, 198, 373, 326]\n    ],\n    'backbone': [\n        [-1, 1, 'Focus', [64, 3]],\n        [-1, 1, 'Conv', [128, 3, 2]],\n        [-1, 3, 'BottleneckCSP', [128]],\n        [-1, 1, 'Conv', [256, 3, 2]],\n        [-1, 9, 'BottleneckCSP', [256]],\n        [-1, 1, 'Conv', [512, 3, 2]],\n        [-1, 9, 'BottleneckCSP', [512]],\n        [-1, 1, 'Conv', [1024, 3, 2]],\n        [-1, 1, 'SPP', [1024, [5, 9, 13]]],\n        [-1, 3, 'BottleneckCSP', [1024, False]]\n    ],\n    'head': [\n        [-1, 1, 'Conv', [512, 1, 1]],\n        [-1, 1, 'nn.Upsample', [None, 2, 'nearest']],\n        [[-1, 6], 1, 'Concat', [1]],\n        [-1, 3, 'BottleneckCSP', [512, False]],\n        [-1, 1, 'Conv', [256, 1, 1]],\n        [-1, 1, 'nn.Upsample', [None, 2, 'nearest']],\n        [[-1, 4], 1, 'Concat', [1]],\n        [-1, 3, 'BottleneckCSP', [256, False]],\n        [-1, 1, 'Conv', [256, 3, 2]],\n        [[-1, 14], 1, 'Concat', [1]],\n        [-1, 3, 'BottleneckCSP', [512, False]],\n        [-1, 1, 'Conv', [512, 3, 2]],\n        [[-1, 10], 1, 'Concat', [1]],\n        [-1, 3, 'BottleneckCSP', [1024, False]],\n        [[17, 20, 23], 1, 'Detect', [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]]]]\n    ],\n    'train': '/kaggle/temp/data/annotations/train.txt',  # Путь к файлу train.txt\n    'val': '/kaggle/temp/data/annotations/val.txt',  # Путь к файлу val.txt\n    'test': '/kaggle/temp/data/annotations/test.txt'  # Путь к файлу test.txt\n}\n\n\n\n# Путь к файлу YAML\nyaml_file_path = os.path.join(output_folder, 'yaml_file.yaml')\n\n# Запись словаря в файл YAML\nwith open(yaml_file_path, 'w') as f:\n    yaml.dump(data, f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n# Клонирование репозитория YOLOv5\n!git clone https://github.com/ultralytics/yolov5.git\n\n# Переход в папку YOLOv5\nos.chdir('yolov5')\n!pip install -r requirements.txt  # install\nmodel = torch.hub.load(\"ultralytics/yolov5\", \"yolov5n\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom yolov5 import train\nimport cv2\nimport pandas as pd\nimport requests\n\ndef download_weights(url, save_path):\n    response = requests.get(url, stream=True)\n    with open(save_path, 'wb') as f:\n        f.write(response.content)\n# URL для загрузки весов модели YOLOv5\nurl = 'https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5n.pt'\nsave_path = '/kaggle/working/yourweights.pth'\n# Загрузка весов YOLOv5 с GitHub\nweights = download_weights(url, save_path)\n#weights = 'yolov5s.pt'  # Путь к предварительно обученным весам модели\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport os\n\n!git clone https://github.com/ultralytics/yolov5.git\n\n# Переход в папку YOLOv5\nos.chdir('yolov5')\n!pip install -r requirements.txt  # install\n\nmodel = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")\n\n# Путь к файлу yaml с конфигурацией обучения\ndata_yaml = '/kaggle/temp/data/yaml_file.yaml'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Настройки обучения\nbatch_size = 16\nepochs = 10\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import StepLR\n\n\nfrom yolov5.models.yolo import Model\nfrom yolov5.utils.dataloaders import LoadImagesAndLabels\nfrom yolov5.utils.loss import ComputeLoss\n\n# Путь к файлу yaml с конфигурацией обучения\n#data_yaml = '/kaggle/temp/data/yaml_file.yaml'\n\n# Загрузка данных для обучения\ndataset = LoadImagesAndLabels(livecell_train_val_images_folder)\n\n# Создание DataLoader для обучения\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n\n# Определение модели\nmodel = Model('/kaggle/temp/data/yaml_file.yaml')\n\n# Определение функции потерь\ncriterion = ComputeLoss\n\n# Определение оптимизатора\nlearning_rate = 0.001\noptimizer = Adam(model.parameters(), lr=learning_rate)\n\n# Определение шедулера для изменения learning rate\nlr_step_size = 5\nlr_gamma = 0.1\nscheduler = StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)\n\n# Перемещение модели на GPU (если доступен)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Цикл обучения\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0.0\n    total_samples = 0\n    log_interval = 10\n\n    for batch_idx, (images, targets) in enumerate(dataloader):\n        images = images.to(device)\n        targets = targets.to(device)\n        \n        # Обнуление градиентов\n        optimizer.zero_grad()\n        \n        # Прямой проход через модель\n        outputs = model.forward(images)\n        \n        # Расчет функции потерь\n        loss, loss_items = criterion(outputs, targets)\n\n        # Обратный проход и обновление весов\n        loss.backward()\n        optimizer.step()\n        \n        # Суммарная потеря во время эпохи\n        total_loss += loss.item()\n        total_samples += targets.shape[0]\n        \n        # Вывод информации о процессе обучения\n        if batch_idx % log_interval == 0:\n            print(f\"Epoch {epoch+1}/{epochs}, Batch {batch_idx}/{len(dataloader)}, Loss: {loss.item():.4f}\")\n    \n    # Печать средней потери в конце эпохи\n    avg_loss = total_loss / len(dataloader)\n    print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.4f}\")\n    \n    # Обновление learning rate\n    scheduler.step()\n\n# Сохранение обученной модели\n# torch.save(model.state_dict(), saved_model_path)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import functional as F\nfrom torchvision.models.detection import maskrcnn_resnet50_fpn\n\n# Загрузка и подготовка данных для обучения Mask R-CNN\n\n# Загрузка аннотаций и изображений\nannotations = load_annotations()  # Функция загрузки аннотаций\nimages = load_images()  # Функция загрузки изображений\n\n# Создание датасета и даталоадера для Mask R-CNN\ndataset = MyCustomDataset(annotations, images)  # Замените на свой класс датасета\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Создание модели Mask R-CNN\nmodel = maskrcnn_resnet50_fpn(pretrained=True)\n\n# Определение оптимизатора и функции потерь для обучения Mask R-CNN\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0005)\ncriterion = MaskRCNNLoss()\n\n# Обучение Mask R-CNN\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0.0\n    \n    for images, targets in dataloader:\n        images = [F.to_tensor(image) for image in images]\n        targets = [{k: v for k, v in t.items()} for t in targets]\n        \n        # Передача данных на GPU (если доступно)\n        images = [image.to(device) for image in images]\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n        \n        # Обновление весов модели\n        optimizer.zero_grad()\n        loss_dict = model(images, targets)\n        loss = sum(loss for loss in loss_dict.values())\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n    \n    # Вывод прогресса обучения\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataloader)}\")\n\n# Сохранение обученной модели Mask R-CNN\ntorch.save(model.state_dict(), \"mask_rcnn_model.pth\")\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()  # Переводим модель в режим оценки (валидации или тестирования)\n\n# Валидация\nwith torch.no_grad():\n    total_loss = 0.0\n    total_iou = 0.0\n    \n    for images, targets in validation_dataloader:  # Замените на свой даталоадер валидации\n        images = [F.to_tensor(image) for image in images]\n        targets = [{k: v for k, v in t.items()} for t in targets]\n        \n        # Передача данных на GPU (если доступно)\n        images = [image.to(device) for image in images]\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n        \n        # Вычисление предсказаний модели\n        predictions = model(images)\n        \n        # Вычисление функции потерь\n        loss_dict = model(images, targets)\n        loss = sum(loss for loss in loss_dict.values())\n        \n        # Вычисление метрики IoU\n        iou = calculate_iou(targets, predictions)\n        \n        total_loss += loss.item()\n        total_iou += iou\n    \n    avg_loss = total_loss / len(validation_dataloader)\n    avg_iou = total_iou / len(validation_dataloader)\n    \n    print(f\"Validation Loss: {avg_loss}, IoU: {avg_iou}\")\n\n# Тестирование\nwith torch.no_grad():\n    total_iou = 0.0\n    \n    for images, targets in test_dataloader:  \n        images = [F.to_tensor(image) for image in images]\n        targets = [{k: v for k, v in t.items()} for t in targets]\n        \n        # Передача данных на GPU (если доступно)\n        images = [image.to(device) for image in images]\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n        \n        # Вычисление предсказаний модели\n        predictions = model(images)\n        \n        # Вычисление метрики IoU\n        iou = calculate_iou(targets, predictions)\n        \n        total_iou += iou\n    \n    avg_iou = total_iou / len(test_dataloader)\n    \n    print(f\"Test IoU: {avg_iou}\")\n\n","metadata":{},"execution_count":null,"outputs":[]}]}
